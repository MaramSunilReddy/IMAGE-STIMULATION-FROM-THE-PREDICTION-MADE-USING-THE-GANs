padding_width = int(IMAGE_SZ / 4)

def get_masked_images(imgs, padding_width):
    padded_imgs = np.copy(imgs)
    pix_avg = np.mean(padded_imgs, axis=(1, 2, 3))
    padded_imgs[:, :, :padding_width, :] = padded_imgs[:, :, -padding_width:, :] = pix_avg.reshape(-1, 1, 1, 1) #calculating mean pixel intensity and place it masked pixels
    return padded_imgs

def crop_and_resize_image(img, img_size):
    source_size = img.size
    if source_size == img_size:
        return img
    img = img.resize(img_size)
    return img
    
def renorm_image(img_norm):
    img_renorm = (img_norm * 255).astype(np.uint8)
    return img_renorm


class DataGenerator(object):
    def __init__(self, root_dir, img_size= (128, 128), batch_size=32, padding_width= 32, validation_rate=0.1):
        self.batch_size = batch_size
        self.img_size = img_size
        self.padding_width = padding_width

        self.reset()
        self.img_file_list = [] # all the images

        for root, dirs, files in os.walk(root_dir):
            for f in files:
                full_path = os.path.join(root, f)
                if imghdr.what(full_path) is None:
                    continue
                self.img_file_list.append(full_path)
        
        validation_size = math.floor(validation_rate*len(self.img_file_list)) #validation dataset size
        self.validation_file_list = self.img_file_list[:validation_size] #### shouldn't this be reverse???
        self.img_file_list = self.img_file_list[validation_size: ]

    def __len__(self):
        return len(self.img_file_list)

    def reset(self):
        self.images = []
        self.points = []
        self.masks = []

    def get_file_generator(self, file_list, shuffle=True):
        while True:
            if shuffle:
                np.random.shuffle(file_list)
            for f in file_list:
                img = crop_and_resize_image(load_img(f), self.img_size) # loading an image and resize
                self.images.append(img_to_array(img))

                if len(self.images) == self.batch_size: # creating a batch
                    imgs = (np.asarray(self.images, dtype=np.float32) / 255.0) * 2 - 1 # Normalizing the Images for an entire batch
                    self.reset()
                    yield get_masked_images(imgs, self.padding_width), imgs # returns both masked and actual images

    def flow(self):
        return self.get_file_generator(self.img_file_list) 

    def validation_flow(self, validation_steps=1):
        return self.get_file_generator(self.validation_file_list, shuffle=False)


def plot_history(loss_history, model_name):
    plt.plot(loss_history['loss'])
    plt.plot(loss_history['val_loss'])
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    # summarize history for loss plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.savefig('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/log/{}'.format(model_name)) #, transparent=True
    plt.close()


def plot_generated_image(generator, data_generator):
    masked_images, images = next(data_generator.validation_flow()) # change this later to Train and Val.. validation flow must be train
    generated_images = generator.predict(masked_images)
    plt.figure(figsize=(3, 6))
    plt.axis('off')
    plt.xticks([])
    plt.yticks([])
    for i in range(5):
        plt.subplot(5, 2, 2* i+1)
        plt.xticks([])
        plt.yticks([])
        plt.imshow((generated_images[i] + 1) / 2)
        plt.subplot(5, 2, 2* i + 2)
        plt.xticks([])
        plt.yticks([])
        plt.imshow((images[i] + 1) / 2)
    plt.savefig('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/log/{}'.format('test')) #, transparent=True
    plt.close()





def get_counter():
    counter = 0

    def inner_func():
        nonlocal counter
        counter += 1
        if counter == 20:
            counter = 0
            return True
        return False
    return inner_func

def printmd(string):
    display(Markdown(string))


def image_and_label(generator, masked_images, real_images, batch_size):
    generated_images = generator.predict(masked_images)
    combined_images = np.concatenate([generated_images, real_images])
    labels = np.concatenate([np.zeros((batch_size, 1), dtype='float32'), np.ones((batch_size, 1), dtype='float32')])
    return combined_images, labels

def train(path, batch_size = 32, epochs = 1000, steps_per_epoch=None):
    input_shape = (128, 128, 3)
    padding_width = 32
    is_log = get_counter()

    data_generator = DataGenerator(path, img_size=(128, 128), batch_size=32, padding_width=padding_width)
    data_size = len(data_generator)
    print('data size: {}'.format(data_size))

    if steps_per_epoch is None:
        steps_per_epoch = data_size // batch_size

    t1_epochs = epochs * 18 // 100
    t2_epcohs = epochs * 2 // 100
    t3_epochs = epochs * 80 // 100


    generator_history = {'loss': [], 'val_loss': []}
    discriminator_history = {'loss': [], 'val_loss': []}
    gan_history = {'loss': [], 'val_loss': []}

class LogCallback(keras.callbacks.Callback):
        def on_batch_end(self, batch, logs=None):
            if is_log():
                generator_history['loss'].append(logs['loss'])
                masked_images, real_images = next(data_generator.validation_flow())
                val_loss = generator.evaluate(masked_images, real_images, batch_size)
                generator_history['val_loss'].append(val_loss)
                plot_history(generator_history, 'Generator')
                plot_generated_image(generator, data_generator)
    
    printmd('Phase 1 - Updating the Generator')
    if os.path.exists('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/generator.h5'):
        generator.load_weights('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/generator.h5')
        generator_history = json.load(open('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/generator_history.json', 'r', encoding='utf-8'))
        print('Get Trained Generator Weight')
    else:
        logcallback_object = LogCallback()
        generator_loss = generator.fit_generator(data_generator.flow(), epochs=t1_epochs, steps_per_epoch=steps_per_epoch, validation_data=data_generator.validation_flow(), validation_steps=2, callbacks=[logcallback_object])
        generator.save_weights('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/generator.h5') 
        generator_history = generator_loss.history   
        json.dump(generator_history, open('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/generator_history.json', 'w', encoding='utf-8'))
    
    json.dump(gan_history, open('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/gan_history.json', 'w', encoding='utf-8'))
    json.dump(discriminator_history, open('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/discriminator_history.json', 'w', encoding='utf-8'))
    json.dump(generator_history, open('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/generator_end_history.json', 'w', encoding='utf-8'))
gan.save_weights('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/gan.h5')
    discriminator.save_weights('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/discriminator.h5')
    generator.save_weights('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/generator_end.h5')

    print('Phase 2 - Updating the Discriminator')
    counter = 0
    for current_epoch in range(t2_epcohs):
        print('Epoch {}/{}'.format(current_epoch, t2_epcohs))
        progressbar = generic_utils.Progbar(steps_per_epoch)
        for data in itertools.islice(data_generator.flow(), None, steps_per_epoch):
            masked_images, real_images = data
            fake_images = generator.predict(masked_images)
            disc_loss_real = discriminator.train_on_batch(real_images, np.ones(batch_size, dtype='float32'))
            disc_loss_fake = discriminator.train_on_batch(fake_images, np.zeros(batch_size, dtype='float32'))

            disc_loss = (disc_loss_real + disc_loss_fake)/2

            progressbar.add(1, values = [('Discriminator Loss', disc_loss)])
            if is_log():
                discriminator_history['loss'].append(float(disc_loss))
                masked_images, real_images = next(data_generator.validation_flow())
                combined_images, labels = image_and_label(generator, masked_images, real_images, batch_size)
                disc_val_loss = discriminator.evaluate(combined_images, labels)
                discriminator_history['val_loss'].append(float(disc_val_loss))
                plot_history(discriminator_history, 'Discriminator')

print('Phase 3 - Training the Generator and Discriminator Adversarially')
    for current_epoch in range(t3_epochs):
        print('Epoch {}/{}'.format(current_epoch, t3_epochs))
        progressbar = generic_utils.Progbar(steps_per_epoch)
        for data in itertools.islice(data_generator.flow(), None, steps_per_epoch):
            masked_images, real_images = data
            fake_images = generator.predict(masked_images)
            disc_loss_real = discriminator.train_on_batch(real_images, np.ones(batch_size, dtype='float32'))
            disc_loss_fake = discriminator.train_on_batch(fake_images, np.zeros(batch_size, dtype='float32'))

            disc_loss = (disc_loss_real + disc_loss_fake)/2

            gan_loss = gan.train_on_batch(masked_images, [real_images, np.ones((batch_size, 1), dtype='float32')])

progressbar.add(1, values = [('Discriminator Loss', disc_loss), ('GAN Loss', gan_loss[0]), ('Generator Loss', gan_loss[1])])

            if is_log():
                discriminator_history['loss'].append(float(disc_loss))
                gan_history['loss'].append(float(gan_loss[0]))
                generator_history['loss'].append(float(gan_loss[1]))
                masked_iamges, real_images = next(data_generator.validation_flow())
                gan_loss = gan.evaluate(masked_iamges, [real_images, np.ones((batch_size, 1), dtype='float32')])
                combined_images, labels = image_and_label(generator, masked_iamges, real_images, batch_size)
                disc_loss = discriminator.evaluate(combined_images, labels)
                discriminator_history['val_loss'].append(float(disc_loss))
                gan_history['val_loss'].append(float(gan_loss[0]))
                generator_history['val_loss'].append(float(gan_loss[1]))
                plot_history(discriminator_history, 'Discriminator')
                plot_history(gan_history, 'GAN')
                plot_history(generator_history, 'Generator')
                plot_generated_image(generator, data_generator)
    
    generator.save_weights('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/generator_end.h5')
    json.dump(generator_history, open('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/generator_end_history.json', 'w', encoding='utf-8'))
    discriminator.save_weights('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/discriminator.h5')
    json.dump(discriminator_history, open('/content/drive/My Drive/Colab Notebooks/CSE676: Deep Learning/Project 2/checkpoint/discriminator_history.json', 'w', encoding='utf-8'))
